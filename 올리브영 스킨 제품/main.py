import streamlit as st
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup
import time
import os
from collections import Counter
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from matplotlib import font_manager

def get_multiple_page(save_path='ì˜¬ì˜_ìŠ¤í‚¨í† ë„ˆ_íŒë§¤ìˆœ.xlsx'):
    browser = webdriver.Chrome()
    results = []
    try:
        for page_idx in range(1, 6):
            url = f'https://www.oliveyoung.co.kr/store/display/getMCategoryList.do?dispCatNo=100000100010013&fltDispCatNo=&prdSort=03&pageIdx={page_idx}'
            browser.get(url)
            time.sleep(2)

            product_elements = browser.find_elements(By.CSS_SELECTOR, 'div.prd_info > a')
            num_products = len(product_elements)

            for product_idx in range(num_products):
                # ì œí’ˆ ìš”ì†Œ ì¬íƒìƒ‰
                product_elements = browser.find_elements(By.CSS_SELECTOR, 'div.prd_info > a')
                product_elements[product_idx].click()
                time.sleep(2)

                soup = BeautifulSoup(browser.page_source, 'html.parser')
                brand = soup.select_one('p.prd_brand').text.strip() if soup.select_one('p.prd_brand') else None
                product_name = soup.select_one('.prd_name').text.strip() if soup.select_one('.prd_name') else None
                price = soup.select_one('div.price > .price-2 > strong').text.strip() if soup.select_one('div.price > .price-2 > strong') else None

                go_composition = browser.find_elements(By.CSS_SELECTOR, 'li#buyInfo > a')
                composition_data = None
                if go_composition:
                    go_composition[0].click()
                    time.sleep(2)
                    soup = BeautifulSoup(browser.page_source, 'html.parser')
                    composition_elements = soup.select('div#artcInfo > dl.detail_info_list > dd')
                    if composition_elements and len(composition_elements) > 6:
                        composition_data = composition_elements[6].text.strip()

                reviews = []
                go_review = browser.find_elements(By.CSS_SELECTOR, 'li#reviewInfo')
                if go_review:
                    go_review[0].click()
                    time.sleep(2)
                    for review_page in range(1, 11):
                        # ë¦¬ë·° ìš”ì†Œ ì¬íƒìƒ‰
                        review_elements = browser.find_elements(By.CSS_SELECTOR, 'div.txt_inner')
                        for review_element in review_elements:
                            reviews.append(review_element.text.strip())
                        try:
                            next_page_btn = browser.find_element(By.XPATH, f"//a[@data-page-no='{review_page + 1}']")
                            browser.execute_script("arguments[0].click();", next_page_btn)
                            time.sleep(2)
                        except:
                            break

                results.append({
                    "ë¸Œëœë“œ": brand,
                    "ìƒí’ˆëª…": product_name,
                    "ê°€ê²©": price,
                    "êµ¬ì„±ì •ë³´": composition_data,
                    "ë¦¬ë·°": reviews
                })
                browser.back()
                time.sleep(2)
    finally:
        browser.quit()

    final_df = pd.DataFrame(results)
    final_df.to_excel('./data/ì˜¬ì˜_ìŠ¤í‚¨í† ë„ˆ_íŒë§¤ìˆœ_ìŠ¤í‚¨íƒ€ì…ë³„.xlsx', index=False)
    return final_df


# @st.cache_data
def load_data(file_path):
    return pd.read_excel(file_path)

# 1. ë§ì´ ì–¸ê¸‰ëœ ë¸Œëœë“œ Top 5 (ìˆ˜ì§‘ ìˆœì„œ ê³ ë ¤)
def get_top_brands_with_order(df, top_n=5):
    brand_counts = df['ë¸Œëœë“œ'].value_counts().reset_index()
    brand_counts.columns = ['ë¸Œëœë“œ', 'ì–¸ê¸‰íšŸìˆ˜']
    
    # ìˆ˜ì§‘ ìˆœì„œë¥¼ ê³ ë ¤í•œ ë¸Œëœë“œ ìˆœì„œ ìœ ì§€
    df['ìˆ˜ì§‘ìˆœì„œ'] = df.index  
    brand_order = df[['ë¸Œëœë“œ', 'ìˆ˜ì§‘ìˆœì„œ']].drop_duplicates(subset=['ë¸Œëœë“œ'], keep='first')

    merged = pd.merge(brand_counts, brand_order, on='ë¸Œëœë“œ')
    merged = merged.sort_values(by=['ì–¸ê¸‰íšŸìˆ˜', 'ìˆ˜ì§‘ìˆœì„œ'], ascending=[False, True])
    
    result = merged.head(top_n).reset_index(drop=True)  
    result.index += 1 

    return result.set_index('ë¸Œëœë“œ')['ì–¸ê¸‰íšŸìˆ˜']

# 2-1. ì„±ë¶„ ë°ì´í„°ì—ì„œ ì œì™¸ ì„±ë¶„ ì œì™¸ í›„ ì›Œë“œí´ë¼ìš°ë“œ
def generate_filtered_wordcloud(df, exclude_list=None, col='êµ¬ì„±ì •ë³´'):
    if exclude_list is None:
        exclude_list = {'ì •ì œìˆ˜', 'ì—íƒ„ì˜¬', 'ì•Œì½”ì˜¬', 'ë³´ìŠµì œ'}
    
    ingredient_data = []
    for ingredients in df[col]:
        if pd.notna(ingredients):
            for ingredient in ingredients.split(', '):
                if ingredient not in exclude_list:
                    ingredient_data.append(ingredient)

    font_path = 'C:/Windows/Fonts/malgun.ttf'
    ingredient_text = ' '.join(ingredient_data)
    wordcloud = WordCloud(
        font_path=font_path,
        width=800,
        height=400,
        background_color='white'
    ).generate(ingredient_text)
   
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    return fig

# 2-2. ê²¹ì¹˜ì§€ ì•ŠëŠ” ì„±ë¶„ë§Œ ì¶”ì¶œ ë° ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
def generate_low_frequency_histogram_and_top5(df, exclude_list=None, col='êµ¬ì„±ì •ë³´', threshold=39, top_n=10):
    if exclude_list is None:
        exclude_list = {'ì •ì œìˆ˜', 'ì—íƒ„ì˜¬', 'ì•Œì½”ì˜¬', 'ë³´ìŠµì œ'}
    
    ingredient_data = []
    for ingredients in df[col]:
        if pd.notna(ingredients):
            for ingredient in ingredients.split(', '):
                if ingredient not in exclude_list:
                    ingredient_data.append(ingredient)
    
    ingredient_counts = Counter(ingredient_data)
    
    low_frequency_ingredients = {ing: count for ing, count in ingredient_counts.items() if count <= threshold}
    
    top_low_freq_ingredients = sorted(low_frequency_ingredients.items(), key=lambda x: x[1], reverse=True)[:top_n]
    
    hist_data = pd.DataFrame(top_low_freq_ingredients, columns=['ì„±ë¶„', 'ì–¸ê¸‰íšŸìˆ˜'])
    hist_data.index += 1
    
    font_path = 'C:/Windows/Fonts/malgun.ttf'  # Windowsìš© í°íŠ¸ ê²½ë¡œ
    font_prop = font_manager.FontProperties(fname=font_path)
    plt.rc('font', family=font_prop.get_name())
    fig, ax = plt.subplots(figsize=(10, 6))
    hist_data.sort_values(by='ì–¸ê¸‰íšŸìˆ˜').plot.barh(
        x='ì„±ë¶„', y='ì–¸ê¸‰íšŸìˆ˜', ax=ax, color='skyblue', legend=False
    )
    ax.set_xlabel('ì–¸ê¸‰ íšŸìˆ˜', fontsize=12)
    ax.set_ylabel('ì„±ë¶„', fontsize=12)
    ax.set_title('40ë²ˆ ë¯¸ë§Œ ì–¸ê¸‰ëœ ì„±ë¶„ Top 10', fontsize=16)
    plt.tight_layout()
    
    return fig, hist_data,


# 3. ì „ì²´ ë§ì´ ì–¸ê¸‰ëœ ì„±ë¶„ Top 5
def get_top_ingredients(df, top_n=5):
    ingredient_data = []
    for ingredients in df['êµ¬ì„±ì •ë³´']:
        if pd.notna(ingredients):
            for ingredient in ingredients.split(', '):
                ingredient_data.append(ingredient)
    
    exclude_list = {'ì •ì œìˆ˜', 'ì—íƒ„ì˜¬', 'ì•Œì½”ì˜¬', 'ë³´ìŠµì œ'}
    filtered_data = [ing for ing in ingredient_data if ing not in exclude_list]
    
    ingredient_counts = Counter(filtered_data)
    top_ingredients = ingredient_counts.most_common(top_n)
    
    result = pd.DataFrame(top_ingredients, columns=['ì„±ë¶„', 'ì–¸ê¸‰íšŸìˆ˜']).reset_index(drop=True)
    result.index += 1  
    return result

# 4. í”¼ë¶€íƒ€ì…ë³„ ë§ì´ ì–¸ê¸‰ëœ ì„±ë¶„ Top 5
def get_top_ingredients_by_skin_type(df, skin_type_col='í”¼ë¶€íƒ€ì…ì¶”ì²œ', top_n=5):
    ingredient_data = []

    for _, row in df.iterrows():
        skin_type = row[skin_type_col]
        ingredients = row['êµ¬ì„±ì •ë³´']
        if pd.notna(skin_type) and pd.notna(ingredients):
            for ingredient in ingredients.split(', '): 
                ingredient_data.append((skin_type, ingredient))
    
    exclude_list = {'ì •ì œìˆ˜', 'ì—íƒ„ì˜¬', 'ì•Œì½”ì˜¬', 'ë³´ìŠµì œ'}
    filtered_data = [(skin_type, ing) for skin_type, ing in ingredient_data if ing not in exclude_list]
    
    skin_type_counts = {}
    for skin_type, ing in filtered_data:
        if skin_type not in skin_type_counts:
            skin_type_counts[skin_type] = Counter()
        skin_type_counts[skin_type][ing] += 1
    
    result = {}
    for skin_type, counts in skin_type_counts.items():
        top_counts = counts.most_common(top_n)
        result[skin_type] = (
            pd.DataFrame(top_counts, columns=['ì„±ë¶„', 'ì–¸ê¸‰íšŸìˆ˜'])
            .reset_index(drop=True)
            .assign(ìˆœìœ„=lambda x: x.index + 1) 
        )
    
    return result

# ë¶ˆìš©ì–´ ì •ì˜
STOPWORDS = {
    'ì˜', 'ì´', 'ê°€', 'ì€', 'ëŠ”', 'ì„', 'ë¥¼', 'ì—', 'ì™€', 'ê³¼', 
    'ë„', 'ìœ¼ë¡œ', 'ë¡œ', 'ì—ì„œ', 'í•˜ê³ ', 'ì…ë‹ˆë‹¤', 'ìˆ˜', 'ìˆë‹¤', 
    'ìˆìŠµë‹ˆë‹¤', 'í•©ë‹ˆë‹¤', 'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ë”', 'ê·¸', 'ë˜', 'í•œ',
    'ë„ˆë¬´', 'ì •ë§', 'ì¢‹ì•„ìš”', 'ì €ëŠ”', 'ì•„ì£¼', 'í”¼ë¶€ê°€', 'ê°™ì•„ìš”', 
    'ê²ƒ', 'í† ë„ˆ', 'í”¼ë¶€', 'ìŠ¤í‚¨', 'ë•Œ', 'ì¢€', 'ì¢‹ì•„ì„œ', 'ë§ì´', 
    'ëŠë‚Œ', 'ì´ê±°', 'ë‹¤ë¥¸', 'ì“°ë©´', 'ì •ë„', 'ìˆëŠ”', 'ì—†ê³ ', 
    'í•­ìƒ', 'ê°™ì´', 'êµ¬ë§¤í–ˆì–´ìš”', 'êµ¬ë§¤', 'ë‹¤ì‹œ', 'ì§„ì§œ', 'n', 
    'ì¼ë‹¨', 'ë°”ë¡œ', 'ê·¸ëƒ¥', 'ì¢‹ì€', 'ì“°ê³ ', 'í”¼ë¶€ì—', 'ë™ìƒì´', 'í–¥ë„', 'ì¢‹ê² ì–´ìš”', 
    'ì¶”ì²œí•©ë‹ˆë‹¤', 'í•œ ë²ˆ', 'ì—„ì²­', 'ì œí’ˆì€', 'ì œí’ˆì´', 'ìƒê°í•©ë‹ˆë‹¤', 'ì œí’ˆì…ë‹ˆë‹¤', 
    'ì¢‹ì•„ìš”', 'ì œê°€', 'ë™ìƒì€', 'ëŠë‚Œì´', 'ì¢‹ì€ê±°', 'ì¢‹ìŠµë‹ˆë‹¤', 'ì´ê²ƒë§Œ', 'ì œí’ˆ', 
    'ë¦¬ë·°', 'ì¡°ê¸ˆ', 'ì—„ì²­', 'ã…ã…', 'ì¢‹ê³ ', 'í™•ì‹¤íˆ', 'ì œí’ˆì„', 'ì™„ì „', 'í† ë„ˆë¥¼', 
    'ìˆì–´ì„œ', 'ì—†ì–´ì„œ', 'ì‚¬ìš©í•´ë„', 'ê¾¸ì¤€íˆ', 'ëŠë‚Œì´ì—ìš”', 'ê·¸ë˜ì„œ', 'êµ‰ì¥íˆ', 
    'ì“°ê³ ', 'ì „ì—', 'ì‚¬ì„œ', 'ìƒê°ë³´ë‹¤', 'ìƒ€ì–´ìš”', 'ê·¼ë°', 'í•´ì„œ', 'ìì£¼', 'íŠ¹íˆ', 
    'ë”°ë¡œ', 'ã… ã… ', 'ë•Œë¬¸ì—', 'ì œí’ˆì´ë¼', 'í•œë²ˆ', 'ê±°ì˜', 'ì›Œë‚™', 'ì´ë ‡ê²Œ', 'ìˆì–´ì„œ', 
    'ì‚¬ìš©', 'ì‚¬ìš©í•˜ê³ ', 'ì‚¬ìš©í•˜ë©´', 'ì•Šê³ ', 'ã…‹ã…‹', 'ëŠë‚Œì´', 'ìˆì–´ìš”', 'êµ¬ë§¤í–ˆëŠ”ë°', 
    'nì €ëŠ”', 'n', 'í† ë„ˆëŠ”', 'ê°™ì•„ìš”', 'ê·¸ëŸ°ì§€', 'ì œí’ˆì´ì—ìš”', 'ë˜ê³ ', 'ìì£¼', 'ë‚˜ì„œ', 
    'ì—„ì²­', 'í† ë„ˆë¥¼', 'í”¼ë¶€ì—', 'ì œí’ˆ', 'í† ë„ˆëŠ”', 'ì¡°ê¸ˆ', 'ê·¸ë˜ì„œ', 'ë•Œë¬¸ì—', 'í•´ì„œ', 
    'ì‚´ì§', 'ì œí’ˆì…ë‹ˆë‹¤', 'ê°™ì•„ì„œ', 'ì‚¬ìš©í•˜ëŠ”ë°', 'ì–¼êµ´ì´', 'êµ¬ë§¤í–ˆìŠµë‹ˆë‹¤', 'ì¶”ì²œí•©ë‹ˆë‹¤', 
    'í•˜ë‚˜', 'ì´ë²ˆì—', 'ì§€ê¸ˆ', 'ì‚¬ìš©í•˜ë©´', 'ìš”ì¦˜', 'ê°€ì¥', 'ì²˜ìŒ', 'ì—¬ëŸ¬ë²ˆ', 'ë°œë¼ë„', 
    'ì´ë ‡ê²Œ', 'ëŠë‚Œì´ë¼','í† ë„ˆê°€', 'ì¢‹ì•˜ì–´ìš”', 'ì¢‹ë„¤ìš”', 'ì–¼êµ´ì—', 'í† ë„ˆë¡œ', 'ê·¸ëŸ°', 
    'ì—†ëŠ”', 'ë§ëŠ”', 'ì¢‹ë‹¤ê³ ', 'ì¢‹ì•„ìš”', 'ê°™ì•„ìš”','í† ë„ˆë„','ê°™ìŠµë‹ˆë‹¤','ì¢‹ì„','ê·¸ë¦¬ê³ ','ì¨ë´¤ëŠ”ë°',
    'ì¢‹ë”ë¼êµ¬ìš”','ì•½ê°„','ë§ëŠ”','ì‚¬ìš©í•˜ê¸°','ê¸ˆë°©','ë­”ê°€','ìˆëŠ”ë°','ì•Šì•„ì„œ','ê°™ì€','ì¢‹ë‹¤ê³ ','ì¢‹ì•˜ì–´ìš”',
    'ì•„ë‹ˆë¼','ê°™ì€','ì—­ì‹œ','ì¢‹ì•„ìš”','ì¢‹ë„¤ìš”','ìˆëŠ”ë°','í•˜ëŠ”','nê·¸ë¦¬ê³ ','ì´ëŸ°','ê°™ìŠµë‹ˆë‹¤','ìˆì–´','ì¢‹ë‹¤ê³ ',
    'ê·¸ë˜ë„','ê³„ì†','ì¢‹ì•„ìš”','ìˆëŠ”ë°','ì—†ëŠ”', 'ë‚¨í¸ì´','í•˜ë”ë¼ê³ ìš”','ì•Šì§€ë§Œ','ìˆì§€ë§Œ','ìˆê³ ','ì¢‹ì€ë°', 'ì´ê±¸ë¡œ',
    'ëŠ˜','ì´ê²Œ','ì´ê±´','ì—†ì´','í¬ë¦¬ë‹ˆí¬','ë‹¤ë§Œ','ê°™ì•„ìš”','ì œí’ˆì—'
}

# ë¶ˆìš©ì–´ ì œê±°
def preprocess_text(text):
    words = text.split() 
    meaningful_words = [word for word in words if word not in STOPWORDS and len(word) > 1]
    return ' '.join(meaningful_words)

def preprocess_reviews(df, review_col='ë¦¬ë·°'):
    df['ì „ì²˜ë¦¬_ë¦¬ë·°'] = df[review_col].dropna().apply(preprocess_text)
    return df

# 5.ë¦¬ë·° ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± (ë¶ˆìš©ì–´ ì œì™¸)
def generate_wordcloud(df, review_col='ì „ì²˜ë¦¬_ë¦¬ë·°'):
    review_text = ' '.join(df[review_col].dropna())
    font_path = 'C:/Windows/Fonts/malgun.ttf'
    wordcloud = WordCloud(
        font_path=font_path, 
        width=800, 
        height=400, 
        background_color='white', 
        stopwords=STOPWORDS 
    ).generate(review_text)
    
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    return fig

# 6. í”¼ë¶€íƒ€ì…ë³„ ë¦¬ë·° ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± (ë¶ˆìš©ì–´ ì œì™¸)
def generate_wordcloud_by_skin_type(df, skin_type_col='í”¼ë¶€íƒ€ì…ì¶”ì²œ', review_col='ì „ì²˜ë¦¬_ë¦¬ë·°'):
    skin_type_reviews = df.groupby(skin_type_col)[review_col].apply(lambda x: ' '.join(x.dropna()))
    skin_type_wordclouds = {}
    font_path = 'C:/Windows/Fonts/malgun.ttf'
    
    for skin_type, review_text in skin_type_reviews.items():
        if review_text: 
            wordcloud = WordCloud(
                font_path=font_path, 
                width=800, 
                height=400, 
                background_color='white', 
                stopwords=STOPWORDS 
            ).generate(review_text)
            
            fig, ax = plt.subplots(figsize=(10, 5))
            ax.imshow(wordcloud, interpolation='bilinear')
            ax.axis('off')
            skin_type_wordclouds[skin_type] = fig
    
    return skin_type_wordclouds

def main():
    st.markdown('## ğŸ«’ì˜¬ë¦¬ë¸Œì˜ [ìŠ¤í‚¨/í† ë„ˆ] íŒë§¤ìˆœ í¬ë¡¤ë§&ë¶„ì„')

    if st.button("ìˆ˜ì§‘í•˜ê¸°"):
        with st.spinner("ë°ì´í„° ìˆ˜ì§‘ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”!"):
            new_data = get_multiple_page()
            new_data['í”¼ë¶€íƒ€ì…ì¶”ì²œ'] = new_data.apply(recommend_skin_type, axis=1)
            new_data.to_excel('./ì˜¬ì˜_ìŠ¤í‚¨í† ë„ˆ_íŒë§¤ìˆœ_ìŠ¤í‚¨íƒ€ì…ë³„.xlsx', index=False, encoding='utf-8-sig')
            st.success("ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥ ì™„ë£Œ!")

    if os.path.exists('./data/ì˜¬ì˜_ìŠ¤í‚¨í† ë„ˆ_íŒë§¤ìˆœ_ìŠ¤í‚¨íƒ€ì…ë³„.xlsx'):
        df = pd.read_excel('./data/ì˜¬ì˜_ìŠ¤í‚¨í† ë„ˆ_íŒë§¤ìˆœ_ìŠ¤í‚¨íƒ€ì…ë³„.xlsx')
    
    category = st.selectbox("ì¹´í…Œê³ ë¦¬ ì„ íƒ", ["ì†Œê°œ","ë°ì´í„° í™œìš© ë° ì†Œê°œ", "ë¸Œëœë“œ", "ì„±ë¶„", "ë¦¬ë·°", "í”¼ë¶€ íƒ€ì…ë³„ ë¦¬ë·° ë° ì„±ë¶„"])
    
    if category == "ì†Œê°œ":
        st.subheader("ğŸ¢ íšŒì‚¬ ì†Œê°œ : ì˜¬ë¦¬ë¸Œì˜")
        st.write(" ì˜¬ë¦¬ë¸Œì˜ì€ ê¸°ì´ˆë¶€í„° ë©”ì´í¬ì—…, ìŠ¤í‚¨ì¼€ì–´ê¹Œì§€ ë‹¤ì–‘í•œ ë·°í‹° ì œí’ˆì„ ì•„ìš°ë¥´ëŠ” ì¢…í•© ë·°í‹° ìŠ¤í† ì–´ì…ë‹ˆë‹¤. \n ë‚˜ì•„ê°€ ë·°í‹°ë¿ë§Œ ì•„ë‹ˆë¼ í—¬ìŠ¤, ë¼ì´í”„ìŠ¤íƒ€ì¼ ì œí’ˆì„ ì œê³µí•˜ëŠ” ëŒ€í•œë¯¼êµ­ì˜ ëŒ€í‘œì ì¸ í—¬ìŠ¤ì•¤ë·°í‹° ìŠ¤í† ì–´ì…ë‹ˆë‹¤. ")
        st.subheader("ğŸ” ì§ë¬´ ì†Œê°œ : MD")
        st.markdown("##### íŠ¸ë Œë“œ ë¶„ì„ ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ì „ëµ ìˆ˜ë¦½ ")
        st.write("   - ë³€í™”í•˜ëŠ” ì‹œì¥ íŠ¸ë Œë“œ ìºì¹­ ë° ì¹´í…Œê³ ë¦¬ ë¶„ì„ í†µí•œ ì „ëµ ìˆ˜ë¦½ \n  - ì „ëµ ê¸°ë°˜ ë‚´/ì™¸ë¶€ ìì› íˆ¬ì… ë¦¬ë”© ")
        st.markdown("#####  ì¹´í…Œê³ ë¦¬ ì „ëµ ê¸°ë°˜ ë¸Œëœë“œ/ìƒí’ˆ ê¸°íš, ë„ì… ë° ìœ¡ì„±  ")
        st.write("   -  ì‹ ê·œ ë¸Œëœë“œ ì†Œì‹± ë° ìƒí’ˆ ê°œë°œ ë° í˜‘ì˜ \n - ë¸Œëœë“œì‚¬ í˜‘ì—… í†µí•œ ë§ˆì¼€íŒ… ë°©í–¥ì„± ê¸°íš ë° ìš´ì˜  ")

    elif category == "ë°ì´í„° í™œìš© ë° ì†Œê°œ":
        st.subheader("âœ… í™œìš©ë„ ë° í™œìš© ë°©ì•ˆ ")
        st.markdown("##### 1. ë¸Œëœë“œ ì¹´í…Œê³ ë¦¬ í™œìš© ")
        st.write("   - ë§¤ì¥ ì§„ì—´ ì „ëµ \n  - ë¸Œëœë“œ ìœ¡ì„± ê³„íš ")
        st.markdown("#####  2. ì„±ë¶„ ì¹´í…Œê³ ë¦¬ í™œìš©  ")
        st.write(" - íŠ¸ë Œë“œ ì„±ë¶„ íŒŒì•…")
        st.markdown("#####  3.í”¼ë¶€ íƒ€ì…ë³„ ì„±ë¶„ & ë¦¬ë·° ë¶„ì„")
        st.write(" - í”¼ë¶€íƒ€ì…ë³„ ì „ëµ : íƒ€ê²Ÿ ê³ ê°ì¸µë³„ ìƒí’ˆ êµ¬ì„±")
        st.write(" - ê³ ê° ë§ì¶¤í˜• ë§ˆì¼€íŒ… : \n í”¼ë¶€íƒ€ì…ë³„ ì£¼ìš” í‚¤ì›Œë“œë¥¼ í™œìš©í•œ ë§ˆì¼€íŒ… ë©”ì‹œì§€ ê°œë°œ, íƒ€ê²Ÿ ê³ ê°ì¸µë³„ ì°¨ë³„í™”ëœ í”„ë¡œëª¨ì…˜ ì„¤ê³„, ì‹œì¦Œë³„ í”¼ë¶€íƒ€ì… ë§ì¶¤ ê¸°íšì „ êµ¬ì„±")
     
        st.subheader("ğŸ’» ë°ì´í„° ì†Œê°œ")
        st.write("ì´ ë°ì´í„°ëŠ” ì˜¬ë¦¬ë¸Œì˜ì—ì„œ íŒë§¤ìˆœìœ¼ë¡œ ì •ë ¬ ëœ ìŠ¤í‚¨ ë° í† ë„ˆ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•œ ê²ƒì…ë‹ˆë‹¤.")
        st.write("ìƒí’ˆëª…, ë¸Œëœë“œ, ê°€ê²©, ì„±ë¶„, ë¦¬ë·° ë“±ì˜ ì •ë³´ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        st.dataframe(df.head())
        st.write("ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™” ì§„í–‰ ê°€ëŠ¥!")
    
    elif category == "ë¸Œëœë“œ":
        st.markdown("## 1ï¸âƒ£ ë§ì´ ì–¸ê¸‰ëœ ë¸Œëœë“œ Top 5")
        top_brands = get_top_brands_with_order(df)
        st.bar_chart(top_brands)
    
    elif category == "ì„±ë¶„":
        st.markdown("## 1ï¸âƒ£ êµ¬ì„± ì„±ë¶„ ì›Œë“œí´ë¼ìš°ë“œ(ê¸°ë³¸ ì„±ë¶„ ì œì™¸)")
        filtered_wordcloud_fig = generate_filtered_wordcloud(df)
        st.pyplot(filtered_wordcloud_fig)

        st.markdown("## 2ï¸âƒ£ ë§ì´ ì–¸ê¸‰ëœ ì„±ë¶„ Top 5(ê¸°ë³¸ ì„±ë¶„ ì œì™¸)")
        top_ingredients = get_top_ingredients(df)
        st.table(pd.DataFrame(top_ingredients, columns=['ì„±ë¶„', 'ì–¸ê¸‰íšŸìˆ˜']))

        st.markdown("## 3ï¸âƒ£ 40ë²ˆ ë¯¸ë§Œ ì–¸ê¸‰ëœ ì„±ë¶„ íˆìŠ¤í† ê·¸ë¨")
        low_freq_hist_fig, low_freq_hist_data = generate_low_frequency_histogram_and_top5(df)
        st.pyplot(low_freq_hist_fig)
        
        st.subheader("40ë²ˆ ë¯¸ë§Œ ì–¸ê¸‰ëœ ì„±ë¶„ Top 10 ë°ì´í„°")
        st.table(low_freq_hist_data)

        st.markdown("## 4ï¸âƒ£ í”¼ë¶€íƒ€ì…ë³„ ë§ì´ ì–¸ê¸‰ëœ ì„±ë¶„ Top 5")
        skin_type_ingredients = get_top_ingredients_by_skin_type(df)
        for skin_type, top_ingredients in skin_type_ingredients.items():
            st.subheader(f"í”¼ë¶€íƒ€ì…: {skin_type}")
            st.table(pd.DataFrame(top_ingredients, columns=['ì„±ë¶„', 'ì–¸ê¸‰íšŸìˆ˜']))
        
    elif category == "ë¦¬ë·°":
        st.markdown("## 1ï¸âƒ£ ë¦¬ë·° ì›Œë“œí´ë¼ìš°ë“œ (ì „ì²´)")
        df = preprocess_reviews(df)  # ì „ì²˜ë¦¬ ì ìš©
        wordcloud_fig = generate_wordcloud(df, review_col='ì „ì²˜ë¦¬_ë¦¬ë·°')  # ì „ì²˜ë¦¬ëœ ë¦¬ë·° ì»¬ëŸ¼ ì‚¬ìš©
        st.pyplot(wordcloud_fig)

        st.markdown("## 2ï¸âƒ£ í”¼ë¶€íƒ€ì…ë³„ ë¦¬ë·° ì›Œë“œí´ë¼ìš°ë“œ")
        skin_type_wordclouds = generate_wordcloud_by_skin_type(df, review_col='ì „ì²˜ë¦¬_ë¦¬ë·°')  # ì „ì²˜ë¦¬ëœ ë¦¬ë·° ì»¬ëŸ¼ ì‚¬ìš©
        for skin_type, wordcloud_fig in skin_type_wordclouds.items():
            st.subheader(f"í”¼ë¶€íƒ€ì…: {skin_type}")
            st.pyplot(wordcloud_fig)

    elif category == "í”¼ë¶€ íƒ€ì…ë³„ ë¦¬ë·° ë° ì„±ë¶„":
        st.markdown("## 1ï¸âƒ£ í”¼ë¶€íƒ€ì…ë³„ ë¦¬ë·° ë° ì„±ë¶„ ë¶„ì„")
        
        skin_type_ingredients = get_top_ingredients_by_skin_type(df)
        df = preprocess_reviews(df)
        skin_type_wordclouds = generate_wordcloud_by_skin_type(df, review_col='ì „ì²˜ë¦¬_ë¦¬ë·°')

        for skin_type in skin_type_ingredients.keys():
            st.subheader(f"í”¼ë¶€íƒ€ì…: {skin_type}")
            
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**ë§ì´ ì–¸ê¸‰ëœ ì„±ë¶„ Top 5**")
                top_ingredients = skin_type_ingredients[skin_type]
                st.table(pd.DataFrame(top_ingredients, columns=['ì„±ë¶„', 'ì–¸ê¸‰íšŸìˆ˜']))
        
            with col2:
                st.markdown("**ë¦¬ë·° ì›Œë“œí´ë¼ìš°ë“œ**")
                st.pyplot(skin_type_wordclouds[skin_type])
        

if __name__ == "__main__":
    main()
